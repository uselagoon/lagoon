apiVersion: v1
kind: Template
metadata:
  creationTimestamp: null
  name: lagoon-openshift-template-fluentd-multi
parameters:
  - name: SERVICE_NAME
    description: Name of this service
    required: true
  - name: SAFE_BRANCH
    description: Which branch this belongs to, special chars replaced with dashes
    required: true
  - name: SAFE_PROJECT
    description: Which project this belongs to, special chars replaced with dashes
    required: true
  - name: BRANCH
    description: Which branch this belongs to, original value
    required: true
  - name: PROJECT
    description: Which project this belongs to, original value
    required: true
  - name: LAGOON_GIT_SHA
    description: git hash sha of the current deployment
    required: true
  - name: SERVICE_ROUTER_URL
    description: URL of the Router for this service
    value: ""
  - name: OPENSHIFT_PROJECT
    description: Name of the Project that this service is in
    required: true
  - name: REGISTRY
    description: Registry where Images are pushed to
    required: true
  - name: SERVICE_IMAGE
    description: Pullable image of service
    required: true
  - name: CRONJOBS
    description: Oneliner of Cronjobs
    value: ""
objects:
- apiVersion: apps/v1beta1
  kind: StatefulSet
  metadata:
    name: ${SERVICE_NAME}
  spec:
    serviceName: ${SERVICE_NAME}
    replicas: 3
    selector:
      matchLabels:
        service: ${SERVICE_NAME}
    template:
      metadata:
        labels:
          branch: ${SAFE_BRANCH}
          project: ${SAFE_PROJECT}
          service: ${SERVICE_NAME}
      spec:
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
                - matchExpressions:
                    - key: lagoon-logs-forwarder
                      operator: NotIn
                      values:
                        - forbidden
          podAntiAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              - labelSelector:
                  matchExpressions:
                    - key: service
                      operator: In
                      values:
                        - ${SERVICE_NAME}
                topologyKey: kubernetes.io/hostname
        containers:
        - name: ${SERVICE_NAME}
          image: ${SERVICE_IMAGE}
          imagePullPolicy: Always
          ports:
          - containerPort: 24284
            protocol: TCP
          readinessProbe:
            tcpSocket:
              port: 24284
            initialDelaySeconds: 20
          livenessProbe:
            tcpSocket:
              port: 24284
            initialDelaySeconds: 120
          env:
            - name: LOGSDB_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: LOGSDB_ADMIN_PASSWORD
                  name: logs-db-admin-password
          envFrom:
          - configMapRef:
              name: lagoon-env
          resources:
            requests:
              cpu: 10m
              memory: 10Mi
          volumeMounts:
          - mountPath: /fluentd/etc/
            name: config
          - mountPath: /fluentd/buffer/
            name: ${SERVICE_NAME}-buffer
        volumes:
        - configMap:
            items:
            - key: FLUENT_CONF
              path: fluent.conf
            - key: LOGS_COPY_FORWARDER_EXTERNAL_FLUENTD
              path: logs-copy-forward-external-fluentd.conf.disabled
            - key: CONTAINER_LOGS_JSON
              path: container-logs.json
            name: ${SERVICE_NAME}-config
          name: config
    volumeClaimTemplates:
      - metadata:
          name: ${SERVICE_NAME}-buffer
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 20G
          storageClassName: lagoon-logs-forwarder
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: null
    labels:
      service: ${SERVICE_NAME}
      branch: ${SAFE_BRANCH}
      project: ${SAFE_PROJECT}
    name: ${SERVICE_NAME}
  spec:
    ports:
    - name: secure-forward
      port: 24284
      protocol: TCP
      targetPort: 24284
    - name: http-metrics
      port: 24231
      protocol: TCP
      targetPort: 24231
    type: NodePort
    selector:
      service: ${SERVICE_NAME}
- apiVersion: v1
  kind: ConfigMap
  metadata:
    name: ${SERVICE_NAME}-config
  data:
    FLUENT_CONF: |-
      <system>
        log_level warn
      </system>

      <source>
        @type secure_forward
        @label @LOGS
        self_hostname "#{ENV['HOSTNAME']}"
        secure true
        port 24284
        shared_key "#{ENV['LOGS_FORWARDER_SHARED_KEY']}"
        ca_cert_path /fluentd/ssl/ca_cert.pem
        ca_private_key_path /fluentd/ssl/ca_key.pem
        ca_private_key_passphrase "#{ENV['LOGS_FORWARDER_PRIVATE_KEY_PASSPHRASE']}"
      </source>

      <source>
        @type prometheus
        bind 0.0.0.0
        port 24231
        metrics_path /metrics
      </source>
      <source>
        @type prometheus_output_monitor
        interval 10
        <labels>
          hostname ${hostname}
        </labels>
      </source>

      <label @LOGS>
        <filter **>
          @type record_modifier
          <record>
            namespace_name "${record['kubernetes']['namespace_name']}"
          </record>
        </filter>
        <filter **>
          @type record_modifier
          <replace>
            # We run automated testing which creates project names in the form of e2e-0000000000-AAAAAAAAAAAAAAAAAAAAAAAAAA
            # we just save them as with the project name 'e2'
            key namespace_name
            expression /^e2e-\\d{10}-\\S{26}$/
            replace e2e
          </replace>
        </filter>
        <filter **>
          @type record_modifier
          <replace>
            # Ansible Service Broker creates individual openshift projects, we put them all in one index
            key namespace_name
            expression /^.*-apb-prov-.*$/
            replace apb-prov
          </replace>
        </filter>
        <filter **>
          @type record_modifier
          <replace>
            # Ansible Service Broker creates individual openshift projects, we put them all in one index
            key namespace_name
            expression /^.*-apb-depr-.*$/
            replace apb-depr
          </replace>
        </filter>
        <filter **>
          @type record_modifier
          <record>
            index_name container-logs-${record['namespace_name']}-${Time.at(time).strftime("%Y.%m")}
          </record>
        </filter>

        <filter **>
          @type record_transformer
          remove_keys viaq_index_name,namespace_name,hostname,$.kubernetes.master_url,$.docker.container_id,$.kubernetes.namespace_id,$.kubernetes.pod_id,$.pipeline_metadata.collector
        </filter>

        <match **>
          @type copy
          <store>
            @type relabel
            @label @LAGOON_ELASTICSEARCH
          </store>

          @include /fluentd/conf.d/logs-copy-*.conf
        </match>
      </label>

      <label @LAGOON_ELASTICSEARCH>
        <match **>
          @type elasticsearch
          #with_transporter_log true
          #@log_level debug
          host "#{ENV['ELASTICSEARCH_HOST']}"
          port "#{ENV['ELASTICSEARCH_HOST_PORT']}"
          templates { "container-logs": "/fluentd/etc/container-logs.json"}
          template_overwrite true
          target_index_key index_name
          index_name container-logs-noproject-%Y.%m
          reconnect_on_error true
          reload_on_failure true
          ssl_version TLSv1_2
          request_timeout 60s
          slow_flush_log_threshold 90s
          <buffer tag,time>
            @type file
            path /fluentd/buffer/elasticsarch
            timekey 3600
            timekey_wait 0s
            flush_mode interval
            flush_interval 10s
            chunk_limit_size 16MB
            total_limit_size 15GB
            flush_thread_count 8
            overflow_action block
            retry_type periodic
            retry_wait 10s
          </buffer>
          id_key viaq_msg_id
          remove_keys viaq_msg_id
          type_name _doc
          user admin
          password "#{ENV['LOGSDB_ADMIN_PASSWORD']}"
        </match>
      </label>
    LOGS_COPY_FORWARDER_EXTERNAL_FLUENTD: |-
      <store>
        @type secure_forward
        self_hostname "#{ENV['HOSTNAME']}"
        secure true
        shared_key "#{ENV['LOGS_FORWARDER_EXTERNAL_FLUENTD_SHARED_KEY']}"
        ca_cert_path "/fluentd/ssl/ca_cert.pem"
        <server>
          host "#{ENV['LOGS_FORWARDER_EXTERNAL_FLUENTD_HOST']}"
          port "#{ENV['LOGS_FORWARDER_EXTERNAL_FLUENTD_PORT']}"
        </server>

        <buffer>
          @type file
          path /fluentd/buffer/external-fluentd
          flush_mode interval
          flush_interval 1s
          chunk_limit_size 256MB
          total_limit_size 15GB
          flush_thread_count 8
        </buffer>
      </store>
    CONTAINER_LOGS_JSON: |-
      {
        "template" : "container-logs-*",
        "version" : 70002,
        "settings" : {
          "index.refresh_interval" : "5s",
          "number_of_shards": 1,
          "number_of_replicas": 1,
          "index.routing.allocation.require.box_type": "live"
        },
        "mappings" : {
          "dynamic_templates" : [ {
            "message_field" : {
              "path_match" : "message",
              "match_mapping_type" : "string",
              "mapping" : {
                "type" : "text",
                "norms" : false
              }
            }
          }, {
            "string_fields" : {
              "match" : "*",
              "match_mapping_type" : "string",
              "mapping" : {
                "type" : "text", "norms" : false,
                "fields" : {
                  "keyword" : { "type": "keyword", "ignore_above": 256 }
                }
              }
            }
          } ],
          "properties" : {
            "@timestamp": { "type": "date"},
            "@version": { "type": "keyword"},
            "geoip"  : {
              "dynamic": true,
              "properties" : {
                "ip": { "type": "ip" },
                "location" : { "type" : "geo_point" },
                "latitude" : { "type" : "half_float" },
                "longitude" : { "type" : "half_float" }
              }
            }
          }
        }
      }