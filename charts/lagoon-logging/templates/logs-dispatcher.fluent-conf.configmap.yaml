apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "lagoon-logging.logsDispatcher.fullname" . }}-fluent-conf
  labels:
    {{- include "lagoon-logging.logsDispatcher.labels" . | nindent 4 }}
data:
  fluent.conf: |
    # vi: ft=fluentd
    <system>
      workers 2
    </system>

    # prometheus metrics
    <source>
      @type prometheus
    </source>
    <source>
      @type prometheus_monitor
    </source>
    <source>
      @type prometheus_output_monitor
    </source>

    # container logs collected by the logging-operator
    <source>
      # fluentd parameters
      @type  forward
      @id    container
      tag    "lagoon.#{ENV['CLUSTER_NAME']}.raw"
    </source>

    # relabel router logs
    # check app name first. if app name didn't match, set tag to container log.
    <match lagoon.*.raw>
      @type rewrite_tag_filter
      <rule>
        key     $.kubernetes.labels.app
        pattern ^nginx-ingress$
        tag     "app-nginx-ingress"
      </rule>
      <rule>
        invert  true
        key     $.kubernetes.labels.app
        pattern ^nginx-ingress$
        tag     "lagoon.#{ENV['CLUSTER_NAME']}.container"
      </rule>
    </match>
    # check namespace_name. if it is okay too, tag as router log.
    # if namespace didn't match, set tag to container log.
    <match app-nginx-ingress>
      @type rewrite_tag_filter
      <rule>
        key     $.kubernetes.namespace_name
        pattern ^syn-nginx-ingress$
        tag     "lagoon.#{ENV['CLUSTER_NAME']}.router"
      </rule>
      <rule>
        invert  true
        key     $.kubernetes.namespace_name
        pattern ^syn-nginx-ingress$
        tag     "lagoon.#{ENV['CLUSTER_NAME']}.container"
      </rule>
    </match>

    # strip the duplicated log field from router logs
    <filter lagoon.*.router>
      @type record_modifier
      remove_keys log
    </filter>

    # logs are now tagged appropriately, so route to labels based on the tag
    <match lagoon.**>
      @type route
      # route _all_ logs container logs (even nginx-ingress) to @container
      <route lagoon.**>
        copy
        @label @container
      </route>
      # route just the router logs to @router
      <route lagoon.*.router>
        copy
        @label @router
      </route>
    </match>

    <label @container>
      # restructure so the kubernetes_metadata plugin can find the keys it needs
      <filter **>
        @type record_modifier
        remove_keys _dummy_
        <record>
          _dummy_ ${record['docker'] = {'container_id' => "#{record.dig('kubernetes','docker_id')}"}; nil}
        </record>
      </filter>
      # enrich with k8s metadata (will get the namespace labels)
      <filter **>
        @type kubernetes_metadata
        @log_level warn
        skip_container_metadata true
        skip_master_url         true
      </filter>
      # strip the duplicate information so that it doesn't appear in logs
      <filter **>
        @type record_modifier
        remove_keys docker
      </filter>
      # add the index_name
      <filter **>
        @type record_modifier
        <record>
          index_name container-logs-${record.dig('kubernetes','namespace_labels','lagoon_sh/project') || "#{record.dig('kubernetes','namespace_name') || 'unknown_project'}_#{ENV['CLUSTER_NAME']}"}-${Time.at(time).strftime("%Y.%m")}
        </record>
      </filter>
      # route to forward block
      <match **>
        @type relabel
        @label @forward
      </match>
    </label>

    <label @router>
      # strip the nginx-ingress namespace info and add enough dummy information
      # so that kubernetes_metadata plugin can get the namespace labels
      <filter **>
        @type record_modifier
        remove_keys _dummy_
        <record>
          _dummy_ ${record['kubernetes'] = {'namespace_name' => record['namespace'], 'pod_name' => 'nopod', 'container_name' => 'nocontainer'}; record['docker'] = {'container_id' => "#{record['namespace']}_#{record['ingress_name']}"}; nil}
        </record>
      </filter>
      # enrich with k8s metadata (will get the namespace labels)
      <filter **>
        @type kubernetes_metadata
        @log_level warn
        skip_container_metadata true
        skip_master_url         true
      </filter>
      # strip the dummy information so that it doesn't appear in logs
      <filter **>
        @type record_modifier
        remove_keys _dummy_,docker
        <record>
          _dummy_ ${record['kubernetes'].delete('pod_name'); record['kubernetes'].delete('container_name'); record['kubernetes'].delete('pod_id'); nil}
        </record>
      </filter>
      # add the index_name
      <filter **>
        @type record_modifier
        <record>
          index_name router-logs-${record.dig('kubernetes','namespace_labels','lagoon_sh/project') || "#{record.dig('kubernetes','namespace_name') || 'unknown_project'}_#{ENV['CLUSTER_NAME']}"}-${Time.at(time).strftime("%Y.%m")}
        </record>
      </filter>
      # route to forward block
      <match **>
        @type relabel
        @label @forward
      </match>
    </label>

    <label @forward>
      # forward to logs-concentrator
      <match **>
        @type forward
        @id out_forward
        # error out early
        verify_connection_at_startup true
        # tls
        transport tls
        tls_cert_path /fluentd/tls/ca.crt
        tls_client_cert_path /fluentd/tls/client.crt
        tls_client_private_key_path /fluentd/tls/client.key
        # endpoint
        <server>
          port "#{ENV['LOGS_FORWARD_HOST_PORT']}"
          host "#{ENV['LOGS_FORWARD_HOST']}"
          name "#{ENV['LOGS_FORWARD_HOSTNAME']}"
          username "#{ENV['LOGS_FORWARD_USERNAME']}"
          password "#{ENV['LOGS_FORWARD_PASSWORD']}"
        </server>
        # authentication
        <security>
          self_hostname "#{ENV['LOGS_FORWARD_SELF_HOSTNAME']}"
          shared_key "#{ENV['LOGS_FORWARD_SHARED_KEY']}"
        </security>
        # buffer chunks by tag
        <buffer tag>
          @type file
          path /fluentd/buffer/forward
          # buffer params (per worker)
          total_limit_size 8GB
          # flush params
          flush_thread_count 2
          overflow_action drop_oldest_chunk
        </buffer>
      </match>
    </label>
